{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "importance_list=[]\n",
    "first_ord=[]\n",
    "score_list = []\n",
    "pvalue_list =[]\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "ypred=[]\n",
    "ytest=[]\n",
    "\n",
    "import json\n",
    "\n",
    "with open('configAMPSIT.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "totalhours = config['totalhours']\n",
    "variables = config['variables']\n",
    "regions = config['regions']\n",
    "verticalmax = config['verticalmax']\n",
    "totalsim = config['totalsim']\n",
    "parameter_names = config['parameter_names']\n",
    "output_path = config['output_pathname']\n",
    "tun_iter = config['tun_iter']\n",
    "    \n",
    "#############################################################################################         \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def sa_randomforest(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun):\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from joblib import dump, load\n",
    "\n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "  \n",
    "    params = {\n",
    "        'n_estimators': (10, 30),  \n",
    "        'max_depth': (2, 6),  \n",
    "        'min_samples_split': (2, 10), \n",
    "        'min_samples_leaf': (1, 8),  \n",
    "        'max_features': [None],  \n",
    "        'bootstrap': [True],  \n",
    "    }\n",
    "\n",
    "\n",
    "    opt = BayesSearchCV(rf, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "    opt.fit(X_train, y_train)\n",
    "    \n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_rf_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_rf_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_rf_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    \n",
    "    best_rf_params = {key.replace(\"estimator__\", \"\"): value for key, value in best_params.items() if key.startswith('estimator__')}\n",
    "    rf = RandomForestRegressor(**best_rf_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "\n",
    "    dump(rf, output_path+'rf_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'rf_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "      \n",
    "    else:            \n",
    "\n",
    "      rf = RandomForestRegressor(n_estimators=20, max_depth=5, max_features='log2',min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      rf.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = rf.predict(X_test)\n",
    "\n",
    "      importances = rf.feature_importances_\n",
    "\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_xgboost(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun):\n",
    "  from xgboost import XGBRFRegressor\n",
    "  from joblib import dump, load\n",
    "\n",
    "  \n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    gb = XGBRFRegressor()\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': (10, 30),\n",
    "        'max_depth': (2, 6),\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(gb, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_xgb_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_xgb_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_xgb_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    gb = XGBRFRegressor(**best_params)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "  \n",
    "    y_pred = gb.predict(X_test)\n",
    "    \n",
    "    importances = gb.feature_importances_\n",
    "\n",
    "    dump(gb, output_path+'xgb_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "\n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'xgb_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "      \n",
    "    else:        \n",
    "    \n",
    "      gb = XGBRFRegressor(n_estimators=20, max_depth=5, max_features='log2',min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      gb.fit(X_train, y_train)\n",
    "    \n",
    "      y_pred = gb.predict(X_test)\n",
    "\n",
    "      importances = gb.feature_importances_\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_cart(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun):\n",
    "  from sklearn.tree import DecisionTreeRegressor\n",
    "  \n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    dt = DecisionTreeRegressor()\n",
    "\n",
    "    params = {\n",
    "        'max_depth': (2, 6),\n",
    "        'min_samples_split': (2, 10),\n",
    "        'min_samples_leaf': (1, 5)\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(dt, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_cart_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_cart_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_cart_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    \n",
    "    dt_params = {key: value for key, value in best_params.items() if key in ['max_depth', 'min_samples_split', 'min_samples_leaf']}\n",
    "\n",
    "    dt = DecisionTreeRegressor(**dt_params)\n",
    "\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    importances = dt.feature_importances_\n",
    "\n",
    "    dump(dt, output_path+'cart_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'cart_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "      \n",
    "    else:    \n",
    "    \n",
    "      dt = DecisionTreeRegressor(max_depth=5,min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      dt.fit(X_train, y_train)\n",
    "\n",
    "      y_pred = dt.predict(X_test)\n",
    "\n",
    "      importances = dt.feature_importances_\n",
    "\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "\n",
    "def sa_lassoregression(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun):\n",
    "  import numpy as np\n",
    "  from sklearn.linear_model import LassoCV\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    lasso_cv = LassoCV()\n",
    "\n",
    "    params = {\n",
    "        'eps': (1e-8, 1e-1, 'log-uniform'),\n",
    "        'n_alphas': (50, 300),\n",
    "        'tol': (1e-8, 1e-3, 'log-uniform'),\n",
    "        'cv': [5, 7],\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(lasso_cv, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_lasso_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_lasso_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_lasso_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    y_pred = opt.best_estimator_.predict(X_test)\n",
    "\n",
    "    importances = np.abs(opt.best_estimator_.coef_)\n",
    "\n",
    "    dump(opt, output_path+'lasso_model_'+f[:-4]+'.joblib')\n",
    "\n",
    "  else:\n",
    "  \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'lasso_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = np.abs(loaded_model.best_estimator_.coef_)\n",
    "      \n",
    "    else:\n",
    "  \n",
    "  \n",
    "      lasso_cv = LassoCV(cv=5)\n",
    "      \n",
    "      lasso_cv.fit(X_train, y_train)                        \n",
    "\n",
    "      y_pred = lasso_cv.predict(X_test)\n",
    "      \n",
    "      importances = np.abs(lasso_cv.coef_)\n",
    "                      \n",
    "  \n",
    "       \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      #importance_list.append(importances)\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "  else:\n",
    "      importance_list = []\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "def sa_svm(X_train, X_test, y_train, y_test, problem, N, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun):\n",
    "  from sklearn import svm\n",
    "  from joblib import dump, load\n",
    "  from sklearn.model_selection import train_test_split, cross_val_score \n",
    "  \n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    svm_model = svm.SVR()\n",
    "\n",
    "    \n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    params = {\n",
    "        'C': Real(1e-4, 1e+1, prior='log-uniform'),\n",
    "        'kernel': Categorical(['poly']),\n",
    "        'gamma': Real(1e-3, 1e+1, prior='log-uniform'), \n",
    "        'epsilon': Real(1e-4, 1e-1, prior='log-uniform'), \n",
    "        'degree': Integer(2, 6),\n",
    "        'coef0': Real(0, 10),\n",
    "    }\n",
    "\n",
    "\n",
    "    svr = BayesSearchCV(svm_model, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(svr, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_svm_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_svm_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_svm_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(svr.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    y_pred = svr.predict(X_test)\n",
    "    coef = svr.best_estimator_.coef_[0]\n",
    "    \n",
    "    dump(svr, output_path+'svm_model_'+f[:-4]+'.joblib')\n",
    "  \n",
    "  else:\n",
    " \n",
    "    if tun==2:\n",
    "      svr = load(output_path+'svm_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = svr.predict(X_test)\n",
    "      \n",
    "      coef=svr.best_estimator_.coef_[0]\n",
    "      \n",
    "    else:\n",
    "      \n",
    "      svr = svm.SVR(kernel='linear', C=1, epsilon=0.1)\n",
    "      svr.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = svr.predict(X_test)\n",
    "      \n",
    "      coef=svr.coef_[0]\n",
    "  \n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(np.abs(coef))\n",
    "      normalized_importances = coef / sum_importances      \n",
    "      importance_list.append(normalized_importances)    \n",
    "  else:\n",
    "      importance_list = []\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_baesyanreg(X_train, X_test, y_train, y_test,problem,N, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,first_ord,f,tun):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  from sklearn.linear_model import BayesianRidge\n",
    "  from joblib import dump, load\n",
    "\n",
    "\n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    br_model = BayesianRidge()\n",
    "\n",
    "    params = {\n",
    "        'n_iter': (100, 500),  \n",
    "        'tol': (1e-9, 1e-3, 'log-uniform'),\n",
    "        'alpha_1': (1e-10, 1e-4, 'log-uniform'),  \n",
    "        'alpha_2': (1e-10, 1e-4, 'log-uniform'),  \n",
    "        'lambda_1': (1e-10, 1e-4, 'log-uniform'),  \n",
    "        'lambda_2': (1e-10, 1e-4, 'log-uniform'), \n",
    "        'fit_intercept': [True, False], \n",
    "    }\n",
    "\n",
    "\n",
    "    br = BayesSearchCV(br_model, params, n_iter=tun_iter, cv=5, n_jobs=-1)\n",
    "\n",
    "    br.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(br, X_train, y_train, cv=5).mean()\n",
    "    \n",
    "    if os.path.exists(f'{output_path}tuning_results_br_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_br_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_br_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(br.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "    \n",
    "    dump(br, output_path+'br_model_'+f[:-4]+'.joblib')\n",
    "    y_pred = br.predict(X_test)\n",
    "    \n",
    "  else:    \n",
    "    if tun==2:\n",
    "      br = load(output_path+'br_model_'+f[:-4]+'.joblib')\n",
    "      y_pred = br.predict(X_test)\n",
    "    else:\n",
    "      br = BayesianRidge()\n",
    "      br.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = br.predict(X_test)\n",
    "\n",
    "\n",
    "  from SALib.sample import sobol\n",
    "  X_sobol = sobol.sample(problem, N, calc_second_order=True)\n",
    "  from numpy import zeros\n",
    "  Y_sobol = zeros((len(X_sobol), 1))\n",
    "  for i in range(len(X_sobol)):\n",
    "      Y_sobol[i] = br.predict(X_sobol[i].reshape(1, -1))\n",
    "  Y_sobol = Y_sobol.reshape(-1)\n",
    "  from SALib.analyze import sobol\n",
    "  Si = sobol.analyze(problem, Y_sobol, calc_second_order=True, print_to_console=False)\n",
    "\n",
    "  importances = Si['ST']\n",
    "  first_order = Si['S1']\n",
    "  interactions=Si['S2']\n",
    "  np.savetxt(output_path+f'interactions_matrix_{len(importance_list)}.txt', interactions, delimiter='\\t', fmt='%f')\n",
    "  \n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "      #importance_list.append(importances)\n",
    "      first_ord.append(first_order)\n",
    "  else:\n",
    "      importance_list = []\n",
    "      first_ord=[]\n",
    "\n",
    "\n",
    "  from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value  \n",
    "  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[] \n",
    "\n",
    "def sa_gaussianreg(X_train, X_test, y_train, y_test,problem,N, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,first_ord,f,tun):\n",
    "\n",
    "  from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process.kernels import Matern\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score  \n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, Sum, Product\n",
    "        \n",
    "    kernel = RBF()\n",
    "    gp_model = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "    params = {\n",
    "        'alpha': Real(1e-8, 1e+3, prior='log-uniform'),\n",
    "        'n_restarts_optimizer': Integer(0, 20),\n",
    "        'kernel__length_scale': Real(1e-2, 1e+2, prior='log-uniform'),\n",
    "    }    \n",
    "\n",
    "    gp = BayesSearchCV(gp_model, params, n_iter=tun_iter, cv=5,n_jobs=-1)\n",
    "    gp.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(gp, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_gp_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_gp_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_gp_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(gp.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "    \n",
    "    dump(gp, output_path+'gp_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "    y_pred = gp.predict(X_test)\n",
    "        \n",
    "  else:  \n",
    "    \n",
    "    if tun==2:\n",
    "      gp = load(output_path+'gp_model_'+f[:-4]+'.joblib')\n",
    "      y_pred = gp.predict(X_test)\n",
    "    else:\n",
    "      kernel = RBF(length_scale=1.0) ##########################################################\n",
    "      gp = GaussianProcessRegressor(kernel=kernel)\n",
    "      gp.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = gp.predict(X_test)\n",
    "  \n",
    "  \n",
    "  from SALib.sample import sobol\n",
    "  X_sobol = sobol.sample(problem, N, calc_second_order=True)\n",
    "  from numpy import zeros\n",
    "  Y_sobol = zeros((len(X_sobol), 1))\n",
    "  for i in range(len(X_sobol)):\n",
    "      Y_sobol[i] = gp.predict(X_sobol[i].reshape(1, -1))\n",
    "  Y_sobol = Y_sobol.reshape(-1)\n",
    "  from SALib.analyze import sobol\n",
    "  Si = sobol.analyze(problem, Y_sobol, calc_second_order=True, print_to_console=False)\n",
    "\n",
    "  importances = np.where(Si['ST'] < 1, Si['ST'], np.nan)\n",
    "  first_order=Si['S1']\n",
    "  interactions=Si['S2']\n",
    "  np.savetxt(output_path+f'interactions_matrix_{len(importance_list)}.txt', interactions, delimiter='\\t', fmt='%f')\n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "      #importance_list.append(importances)\n",
    "      first_ord.append(first_order)\n",
    "  else:\n",
    "      importance_list = []\n",
    "      first_ord=[]\n",
    "\n",
    "  from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "  \n",
    "\n",
    "#############################################################################################\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "file_loop = \"C:/Users/dario/Documents/MATLABdott/WRF_IDEAL_SIMUL/loopconfigseabreezeSCALED.json\"\n",
    "\n",
    "with open(file_loop, 'r') as json_file:\n",
    "    config_data = json.load(json_file)\n",
    "\n",
    "\n",
    "hour=config_data['hour'] \n",
    "n_sample=config_data['Nsobol'] #mod nparam+2 == 0\n",
    "        \n",
    "tun = config_data['tun']      \n",
    "\n",
    "\n",
    "for meth in config_data.get(\"methh\", []):\n",
    "  for N in config_data.get(\"NN\", []):\n",
    "    for var in config_data.get(\"varr\", []):\n",
    "      for vpoint in config_data.get(\"vpointt\", []):\n",
    "        for hpoint in config_data.get(\"hpointt\", []):\n",
    "\n",
    "          if var >= 1 and var <= len(variables):\n",
    "              nam1 = variables[var - 1]\n",
    "          else:\n",
    "              nam1 = 'Invalid var value'\n",
    "\n",
    "          if hpoint >= 1 and hpoint <= len(regions):\n",
    "              nam2 = regions[hpoint - 1]\n",
    "          else:\n",
    "              nam2 = 'Invalid hpoint value'        \n",
    "\n",
    "          name=nam1+'_'+nam2+'_lev'+str(vpoint)\n",
    "          file_list=[nam1+'_'+nam2+'_lev'+str(vpoint)+'_'+str(i)+'.txt' for i in range(1,totalhours+1)]\n",
    "          \n",
    "          Xnonscaled = np.loadtxt(output_path+'X.txt') \n",
    "\n",
    "\n",
    "          for file in file_list:\n",
    "\n",
    "            f = file\n",
    "            ynonscaled = np.loadtxt(output_path+file, delimiter=',')\n",
    "            \n",
    "            if N==int(totalsim-190):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-190),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-190)]\n",
    "            elif N==int(totalsim-180):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-180),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-180)]\n",
    "            elif N==int(totalsim-170):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-170),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-170)]\n",
    "            elif N==int(totalsim-160):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-160),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-160)] \n",
    "            elif N==int(totalsim-150):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-150),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-150)]\n",
    "            elif N==int(totalsim-140):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-140),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-140)]\n",
    "            elif N==int(totalsim-130):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-130),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-130)]\n",
    "            elif N==int(totalsim-120):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-120),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-120)]\n",
    "            elif N==int(totalsim-110):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-110),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-110)]\n",
    "            elif N==int(totalsim-100):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-100),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-100)]            \n",
    "            if N==int(totalsim-90):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-90),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-90)]\n",
    "            elif N==int(totalsim-80):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-80),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-80)]\n",
    "            elif N==int(totalsim-70):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-70),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-70)]\n",
    "            elif N==int(totalsim-60):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-60),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-60)] \n",
    "            elif N==int(totalsim-50):\n",
    "              Xnonscaled = Xnonscaled[:int(totalsim-50),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-50)]\n",
    "            elif N==int(totalsim-40):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-40),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-40)]\n",
    "            elif N==int(totalsim-30):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-30),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-30)]\n",
    "            elif N==int(totalsim-20):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-20),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-20)]\n",
    "            elif N==int(totalsim-10):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-10),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-10)]\n",
    "            elif N==int(totalsim-0):\n",
    "              Xnonscaled= Xnonscaled[:int(totalsim-0),:]\n",
    "              ynonscaled = ynonscaled[:int(totalsim-0)]\n",
    "            \n",
    "\n",
    "            y=ynonscaled\n",
    "            X=Xnonscaled            \n",
    "            \n",
    "            \n",
    "            from sklearn.model_selection import train_test_split\n",
    "            \n",
    "            partition=0.3\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=partition, random_state=42)\n",
    "\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            from joblib import dump\n",
    "\n",
    "            ##########################\n",
    "            ########\n",
    "\n",
    "            scalerX = StandardScaler()\n",
    "            X_train = scalerX.fit_transform(X_train)\n",
    "            X_test = scalerX.transform(X_test)\n",
    "\n",
    "            scalery = StandardScaler()\n",
    "            y_train = scalery.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "            y_test = scalery.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "            \n",
    "            ''\n",
    "            Xlow = np.min(X_train, axis=0)\n",
    "            Xup = np.max(X_train, axis=0)\n",
    "            Nn = n_sample \n",
    "            bounds = [(Xlow[i], Xup[i]) for i in range(Xlow.shape[0])]\n",
    "            problem = {'num_vars': X.shape[1], 'names': parameter_names, 'bounds': bounds}            \n",
    "            ''\n",
    "            \n",
    "            \n",
    "            if meth==1:\n",
    "              Si = sa_randomforest(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun)\n",
    "              method='randomforest'\n",
    "            elif meth==2:\n",
    "              Si = sa_lassoregression(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun)\n",
    "              method='lasso'\n",
    "            elif meth==3:\n",
    "              Si = sa_svm(X_train, X_test, y_train, y_test,problem,Nn, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun)\n",
    "              method='svm'\n",
    "            elif meth==4:        \n",
    "              Si = sa_baesyanreg(X_train, X_test, y_train, y_test,problem,Nn, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,first_ord,f,tun)\n",
    "              method='br'\n",
    "            elif meth==5:\n",
    "              Si = sa_gaussianreg(X_train, X_test, y_train, y_test,problem,Nn, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,first_ord,f,tun)\n",
    "              method='gp'\n",
    "            elif meth==6:\n",
    "              Si = sa_xgboost(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun)\n",
    "              method='xgboost'              \n",
    "            elif meth==7:\n",
    "              Si = sa_cart(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,f,tun)\n",
    "              method='cart'\n",
    "              \n",
    "                          \n",
    "            data = np.array([score_list, pvalue_list, mse_list, mae_list]).T\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame(data, columns=['score', 'pvalue' , 'mse', 'mae'])\n",
    "            importance_df = pd.DataFrame(importance_list)\n",
    "            if hour==totalhours:\n",
    "              importance_df.to_csv(output_path+'importance'+method+str(N)+file[:-7]+'.txt', header=False, index=False, sep=' ')\n",
    "              df.to_csv(output_path+'df'+method+str(N)+file[:-7]+'.txt', header=False, index=False, sep=' ')\n",
    "              yt=np.array(ytest)\n",
    "              yp=np.array(ypred)\n",
    "              \n",
    "          \n",
    "          importance_list=[]\n",
    "          first_ord=[]\n",
    "          score_list = []\n",
    "          pvalue_list =[]\n",
    "          mse_list = []\n",
    "          mae_list = []\n",
    "          ypred=[]\n",
    "          ytest=[]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
