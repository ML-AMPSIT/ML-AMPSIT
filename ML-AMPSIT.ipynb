{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbd928a1c034d18b8716ffed1184d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<br>'), HTML(value=\"<h1 style='margin-top: 20px; text-align: center; font-family: Aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importare le librerie necessarie\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "importance_list=[]\n",
    "first_ord=[]\n",
    "score_list = []\n",
    "pvalue_list =[]\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "ypred=[]\n",
    "ytest=[]\n",
    "\n",
    "import json\n",
    "\n",
    "with open('configAMPSIT.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "totalhours = config['totalhours']\n",
    "variables = config['variables']\n",
    "regions = config['regions']\n",
    "verticalmax = config['verticalmax']\n",
    "totalsim = config['totalsim']\n",
    "parameter_names = config['parameter_names']\n",
    "output_path = config['output_pathname']\n",
    "tun_iter = config['tun_iter']\n",
    "    \n",
    "#############################################################################################         \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def sa_randomforest(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f):\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': (10, 30),\n",
    "        'max_depth': (2, 6),\n",
    "        'min_samples_split': (2, 5),\n",
    "        'min_samples_leaf': (1, 5),\n",
    "        'max_features': ('sqrt', 'log2')\n",
    "    }\n",
    "\n",
    "\n",
    "    opt = BayesSearchCV(rf, params, n_iter=tun_iter, cv=5)\n",
    "    opt.fit(X_train, y_train)\n",
    "    \n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_rf_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_rf_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_rf_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    best_rf_params = {key.replace(\"estimator__\", \"\"): value for key, value in best_params.items() if key.startswith('estimator__')}\n",
    "    rf = RandomForestRegressor(**best_rf_params)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    \n",
    "    sum_importances = np.sum(importances, axis=0)\n",
    "    normalized_importances = importances / sum_importances\n",
    "\n",
    "    dump(rf, output_path+'rf_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'rf_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "    \n",
    "    \n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances  \n",
    "      \n",
    "    else:            \n",
    "\n",
    "      rf = RandomForestRegressor(n_estimators=20, max_depth=5, max_features='log2',min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      rf.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = rf.predict(X_test)\n",
    "\n",
    "      importances = rf.feature_importances_\n",
    "      \n",
    "      \n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "      #importance_list.append(normalized_importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "  \n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "          \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_xgboost(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f):\n",
    "  import xgboost as xgb\n",
    "  from xgboost import XGBRFRegressor\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  xgb.set_config(verbosity=0)\n",
    "\n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    gb = XGBRFRegressor()\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': (10, 30),\n",
    "        'max_depth': (2, 6),\n",
    "        'min_samples_split': (2, 5),\n",
    "        'min_samples_leaf': (1, 5),\n",
    "        'max_features': ('sqrt', 'log2')\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(gb, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_xgb_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_xgb_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_xgb_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    gb = XGBRFRegressor(**best_params)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "  \n",
    "    y_pred = gb.predict(X_test)\n",
    "    \n",
    "    importances = gb.feature_importances_\n",
    "\n",
    "    dump(gb, output_path+'xgb_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "\n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'xgb_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "      \n",
    "    else:        \n",
    "    \n",
    "      gb = XGBRFRegressor(n_estimators=20, max_depth=5, max_features='log2',min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      gb.fit(X_train, y_train)\n",
    "    \n",
    "      y_pred = gb.predict(X_test)\n",
    "\n",
    "      importances = gb.feature_importances_\n",
    "\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "            \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_cart(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f):\n",
    "  from sklearn.tree import DecisionTreeRegressor\n",
    "  from joblib import dump, load\n",
    "\n",
    "  if tun==1:\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    dt = DecisionTreeRegressor()\n",
    "\n",
    "    params = {\n",
    "        'max_depth': (2, 6),\n",
    "        'min_samples_split': (2, 5),\n",
    "        'min_samples_leaf': (1, 5)\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(dt, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_cart_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_cart_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_cart_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    best_params = opt.get_params()\n",
    "    dt_params = {key: value for key, value in best_params.items() if key in ['max_depth', 'min_samples_split', 'min_samples_leaf']}\n",
    "\n",
    "    dt = DecisionTreeRegressor(**dt_params)\n",
    "\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    importances = dt.feature_importances_\n",
    "\n",
    "    dump(dt, output_path+'cart_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "  else:\n",
    "    \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'cart_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = loaded_model.feature_importances_\n",
    "      \n",
    "    else:    \n",
    "    \n",
    "      dt = DecisionTreeRegressor(max_depth=5,min_samples_leaf= 1, min_samples_split= 2)\n",
    "    \n",
    "      dt.fit(X_train, y_train)\n",
    "\n",
    "      y_pred = dt.predict(X_test)\n",
    "\n",
    "      importances = dt.feature_importances_\n",
    "\n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      importance_list.append(importances)\n",
    "  else:\n",
    "      importance_list = []               \n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_lassoregression(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f):\n",
    "  import numpy as np\n",
    "  from sklearn.linear_model import LassoCV\n",
    "  from joblib import dump, load\n",
    " \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    lasso_cv = LassoCV(cv=5)\n",
    "\n",
    "    params = {\n",
    "        'eps': (1e-5, 1e-1),\n",
    "        'n_alphas': (50, 200),\n",
    "        'tol': (1e-6, 1e-3)\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(lasso_cv, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_lasso_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_lasso_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_lasso_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    y_pred = opt.best_estimator_.predict(X_test)\n",
    "\n",
    "    importances = np.abs(opt.best_estimator_.coef_)\n",
    "\n",
    "    dump(opt, output_path+'lasso_model_'+f[:-4]+'.joblib')\n",
    "\n",
    "  else:\n",
    "  \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'lasso_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      importances = np.abs(loaded_model.coef_)\n",
    "      \n",
    "    else:\n",
    "  \n",
    "  \n",
    "      lasso_cv = LassoCV(cv=5)\n",
    "      \n",
    "      lasso_cv.fit(X_train, y_train)                        \n",
    "\n",
    "      y_pred = lasso_cv.predict(X_test)\n",
    "      \n",
    "      importances = np.abs(lasso_cv.coef_)           \n",
    "                      \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "  else:\n",
    "      importance_list = []\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "def sa_svm(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f):\n",
    "  from sklearn import svm\n",
    "  \n",
    "  from sklearn.model_selection import train_test_split, cross_val_score \n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    svm_model = svm.SVR()\n",
    "\n",
    "    params = {\n",
    "        'C': (1e-3, 1e+3, 'log-uniform'),\n",
    "        'kernel': ['linear'],\n",
    "        'gamma': (1e-3, 1e+1, 'log-uniform'),\n",
    "        'epsilon': (1e-4, 1e-1, 'log-uniform'),\n",
    "    }\n",
    "\n",
    "    opt = BayesSearchCV(svm_model, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(opt, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_svm_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_svm_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_svm_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(opt.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "\n",
    "    y_pred = opt.predict(X_test)\n",
    "    coef = opt.best_estimator_.coef_[0]  \n",
    "    \n",
    "    dump(opt, output_path+'svm_model_'+f[:-4]+'.joblib')\n",
    "  \n",
    "  else:\n",
    " \n",
    "    if tun==2:\n",
    "      loaded_model = load(output_path+'svm_model_'+f[:-4]+'.joblib')\n",
    "      \n",
    "      y_pred = loaded_model.predict(X_test)\n",
    "      \n",
    "      coef=loaded_model.coef_[0]\n",
    "      \n",
    "    else:\n",
    "      \n",
    "      clf = svm.SVR(kernel='linear', C=1, epsilon=0.1)\n",
    "      clf.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = clf.predict(X_test)\n",
    "      \n",
    "      coef=clf.coef_[0]\n",
    "\n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(np.abs(coef))\n",
    "      normalized_importances = coef / sum_importances      \n",
    "      importance_list.append(normalized_importances)\n",
    "  else:\n",
    "      importance_list = []\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "def sa_baesyanreg(X_train, X_test, y_train, y_test,problem,N, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,first_ord,f):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  from sklearn.linear_model import BayesianRidge\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    br_model = BayesianRidge()\n",
    "\n",
    "    params = {\n",
    "        'n_iter': (100, 300),\n",
    "        'tol': (1e-6, 1e-3, 'log-uniform'),\n",
    "        'alpha_1': (1e-9, 1e-5, 'log-uniform'),\n",
    "        'alpha_2': (1e-9, 1e-5, 'log-uniform'),\n",
    "        'lambda_1': (1e-9, 1e-5, 'log-uniform'),\n",
    "        'lambda_2': (1e-9, 1e-5, 'log-uniform'),\n",
    "    }\n",
    "\n",
    "    br = BayesSearchCV(br_model, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    br.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(br, X_train, y_train, cv=5).mean()\n",
    "    \n",
    "    if os.path.exists(f'{output_path}tuning_results_br_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_br_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_br_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(br.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "    \n",
    "    dump(br, output_path+'br_model_'+f[:-4]+'.joblib')\n",
    "    y_pred = br.predict(X_test)\n",
    "    \n",
    "  else:    \n",
    "    if tun==2:\n",
    "      br = load(output_path+'br_model_'+f[:-4]+'.joblib')\n",
    "      y_pred = br.predict(X_test)\n",
    "    else:\n",
    "      br = BayesianRidge()\n",
    "      br.fit(X_train, y_train)\n",
    "      \n",
    "      y_pred = br.predict(X_test)\n",
    "\n",
    "  ''\n",
    "  from SALib.sample import sobol\n",
    "  X_sobol = sobol.sample(problem, N, calc_second_order=True)\n",
    "  from numpy import zeros\n",
    "  Y_sobol = zeros((len(X_sobol), 1))\n",
    "  for i in range(len(X_sobol)):\n",
    "      Y_sobol[i] = br.predict(X_sobol[i].reshape(1, -1))\n",
    "  Y_sobol = Y_sobol.reshape(-1)\n",
    "  from SALib.analyze import sobol\n",
    "  Si = sobol.analyze(problem, Y_sobol, calc_second_order=True, print_to_console=False)\n",
    "  ''\n",
    "\n",
    "  importances = Si['ST']\n",
    "  first_order=Si['S1']\n",
    "\n",
    "  interactions=Si['S2']\n",
    "  np.savetxt(output_path+f'interactions_matrix_{len(importance_list)}.txt', interactions, delimiter='\\t', fmt='%f')\n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "      #importance_list.append(importances)\n",
    "      first_ord.append(first_order)\n",
    "  else:\n",
    "      importance_list = []\n",
    "      first_ord=[]\n",
    "\n",
    "\n",
    "  from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value  \n",
    "  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[] \n",
    "\n",
    "def sa_gaussianreg(X_train, X_test, y_train, y_test,problem,N, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,first_ord,f):\n",
    "\n",
    "  from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from joblib import dump, load\n",
    "  \n",
    "  if tun==1:\n",
    "    \n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.model_selection import cross_val_score  \n",
    "    \n",
    "    kernel = RBF(length_scale=1.0)\n",
    "    gp_model = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "    params = {\n",
    "        'alpha': (1e-10, 1e+1, 'log-uniform'),\n",
    "        'n_restarts_optimizer': (0, 5),\n",
    "    }\n",
    "\n",
    "    gp = BayesSearchCV(gp_model, params, n_iter=tun_iter, cv=5)\n",
    "\n",
    "    gp.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(gp, X_train, y_train, cv=5).mean()\n",
    "\n",
    "    if os.path.exists(f'{output_path}tuning_results_gp_{f[:-4]}.txt'):\n",
    "        os.remove(f'{output_path}tuning_results_gp_{f[:-4]}.txt')\n",
    "    with open(f'{output_path}tuning_results_gp_{f[:-4]}.txt', 'a') as file:\n",
    "        file.write(\"Best parameters: {}\\n\".format(gp.best_params_))\n",
    "        file.write(\"Cross-validation score: {}\\n\".format(score))\n",
    "    \n",
    "    dump(gp, output_path+'gp_model_'+f[:-4]+'.joblib')\n",
    "    \n",
    "    y_pred = gp.predict(X_test)\n",
    "        \n",
    "  else:  \n",
    "    \n",
    "    if tun==2:\n",
    "      gp = load(output_path+'gp_model_'+f[:-4]+'.joblib')\n",
    "      y_pred = gp.predict(X_test)\n",
    "    else:\n",
    "      kernel = RBF(length_scale=1.0)\n",
    "      gp = GaussianProcessRegressor(kernel=kernel)\n",
    "      gp.fit(X_train, y_train)\n",
    "      \n",
    "      \n",
    "      y_pred = gp.predict(X_test)\n",
    "\n",
    "  ''\n",
    "  from SALib.sample import sobol\n",
    "  X_sobol = sobol.sample(problem, N, calc_second_order=True)\n",
    "  from numpy import zeros\n",
    "  Y_sobol = zeros((len(X_sobol), 1))\n",
    "  for i in range(len(X_sobol)):\n",
    "      Y_sobol[i] = gp.predict(X_sobol[i].reshape(1, -1))\n",
    "  Y_sobol = Y_sobol.reshape(-1)\n",
    "  from SALib.analyze import sobol\n",
    "  Si = sobol.analyze(problem, Y_sobol, calc_second_order=True, print_to_console=False)\n",
    "  ''\n",
    "  \n",
    "  importances = Si['ST']\n",
    "  first_order=Si['S1']\n",
    "\n",
    "  interactions=Si['S2']\n",
    "  np.savetxt(output_path+f'interactions_matrix_{len(importance_list)}.txt', interactions, delimiter='\\t', fmt='%f')\n",
    "    \n",
    "  \n",
    "  if len(importance_list) <= totalhours-1:\n",
    "      sum_importances = np.sum(importances, axis=0)\n",
    "      normalized_importances = importances / sum_importances       \n",
    "      importance_list.append(normalized_importances)\n",
    "      #importance_list.append(importances)\n",
    "      first_ord.append(first_order)\n",
    "  else:\n",
    "      importance_list = []\n",
    "      first_ord=[]\n",
    "\n",
    "  from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "  \n",
    "  spearman_corr, p_value = spearmanr(y_test, y_pred)\n",
    "  score=spearman_corr\n",
    "  pvalue= p_value  \n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  \n",
    "  if len(score_list) <= totalhours-1:\n",
    "    score_list.append(score)\n",
    "    pvalue_list.append(pvalue)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "  else:\n",
    "    score_list=[]\n",
    "    pvalue_list=[]\n",
    "    mse_list=[]\n",
    "    mae_list=[]\n",
    "\n",
    "  if len(ytest)<=totalhours-1:\n",
    "    ytest.append(y_test)\n",
    "    ypred.append(y_pred)\n",
    "  else:\n",
    "    ytest=[]\n",
    "    ypred=[]\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_predict_and_plot_global(meth,N,var,hpoint,vpoint,hour,tun, n_sample, figsize=(10,6)):\n",
    "  def predict_and_plot(**x_dict):\n",
    "\n",
    "    if var >= 1 and var <= len(variables):\n",
    "        nam1 = variables[var - 1]\n",
    "    else:\n",
    "        nam1 = 'Invalid var value'\n",
    "\n",
    "    if hpoint >= 1 and hpoint <= len(regions):\n",
    "        nam2 = regions[hpoint - 1]\n",
    "    else:\n",
    "        nam2 = 'Invalid hpoint value'        \n",
    "\n",
    "    name=nam1+'_'+nam2+'_lev'+str(vpoint)\n",
    "    file_list=[nam1+'_'+nam2+'_lev'+str(vpoint)+'_'+str(i)+'.txt' for i in range(1,totalhours+1)]\n",
    "\n",
    "    Xnonscaled = np.loadtxt(output_path+'X.txt') \n",
    "\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "      f=file\n",
    "      ynonscaled = np.loadtxt(output_path+file, delimiter=',')\n",
    "      \n",
    "      \n",
    "      if N==int(totalsim*1/10):\n",
    "        Xnonscaled = Xnonscaled[:int(totalsim*1/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*1/10)]\n",
    "      elif N==int(totalsim*2/10):\n",
    "        Xnonscaled = Xnonscaled[:int(totalsim*2/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*2/10)]\n",
    "      elif N==int(totalsim*3/10):\n",
    "        Xnonscaled = Xnonscaled[:int(totalsim*3/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*3/10)]\n",
    "      elif N==int(totalsim*4/10):\n",
    "        Xnonscaled = Xnonscaled[:int(totalsim*4/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*4/10)] \n",
    "      elif N==int(totalsim*5/10):\n",
    "        Xnonscaled = Xnonscaled[:int(totalsim*5/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*5/10)]\n",
    "      elif N==int(totalsim*6/10):\n",
    "        Xnonscaled= Xnonscaled[:int(totalsim*6/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*6/10)]\n",
    "      elif N==int(totalsim*7/10):\n",
    "        Xnonscaled= Xnonscaled[:int(totalsim*7/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*7/10)]\n",
    "      elif N==int(totalsim*8/10):\n",
    "        Xnonscaled= Xnonscaled[:int(totalsim*8/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*8/10)]\n",
    "      elif N==int(totalsim*9/10):\n",
    "        Xnonscaled= Xnonscaled[:int(totalsim*9/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*9/10)]\n",
    "      elif N==int(totalsim*10/10):\n",
    "        Xnonscaled= Xnonscaled[:int(totalsim*10/10),:]\n",
    "        ynonscaled = ynonscaled[:int(totalsim*10/10)]\n",
    "      \n",
    "           \n",
    "      y=ynonscaled\n",
    "      X=Xnonscaled              \n",
    "\n",
    "      from sklearn.model_selection import train_test_split\n",
    "      \n",
    "      partition=0.3\n",
    "        \n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=partition, random_state=42)\n",
    "\n",
    "      from sklearn.preprocessing import StandardScaler\n",
    "      from joblib import dump\n",
    "\n",
    "      scalerX = StandardScaler()\n",
    "      X_train = scalerX.fit_transform(X_train)\n",
    "      X_test = scalerX.transform(X_test)\n",
    "\n",
    "      scalery = StandardScaler()\n",
    "      y_train = scalery.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "      y_test = scalery.transform(y_test.reshape(-1, 1)).ravel()\n",
    "      \n",
    "      ''\n",
    "      Xlow = np.min(X_train, axis=0)\n",
    "      Xup = np.max(X_train, axis=0)\n",
    "      Nn = n_sample \n",
    "      bounds = [(Xlow[i], Xup[i]) for i in range(Xlow.shape[0])]\n",
    "      problem = {'num_vars': X.shape[1], 'names': parameter_names, 'bounds': bounds}            \n",
    "      ''\n",
    "\n",
    "      if meth==1:\n",
    "        Si = sa_randomforest(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f)\n",
    "        method='randomforest'\n",
    "      elif meth==2:\n",
    "        Si = sa_lassoregression(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f)\n",
    "        method='lasso'\n",
    "      elif meth==3:\n",
    "        Si = sa_svm(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f)\n",
    "        method='svm'\n",
    "      elif meth==4:        \n",
    "        Si = sa_baesyanreg(X_train, X_test, y_train, y_test,problem,Nn, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,first_ord,f)\n",
    "        method='br'\n",
    "      elif meth==5:\n",
    "        Si = sa_gaussianreg(X_train, X_test, y_train, y_test,problem,Nn, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,first_ord,f)\n",
    "        method='gp'\n",
    "      elif meth==6:\n",
    "        Si = sa_xgboost(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f)\n",
    "        method='xgb'\n",
    "      elif meth==7:\n",
    "        Si = sa_cart(X_train, X_test, y_train, y_test, importance_list,score_list,pvalue_list,mse_list,mae_list,ytest,ypred,tun,f)\n",
    "        method='cart'                \n",
    "        \n",
    "      data = np.array([score_list, pvalue_list, mse_list, mae_list]).T\n",
    "      \n",
    "      import pandas as pd\n",
    "      df = pd.DataFrame(data, columns=['score', 'pvalue' , 'mse', 'mae'])\n",
    "      importance_df = pd.DataFrame(importance_list)\n",
    "      if hour==totalhours:\n",
    "        importance_df.to_csv(output_path+'importance'+method+str(N)+file[:-7]+'.txt', header=False, index=False, sep=' ')\n",
    "        df.to_csv(output_path+'df'+method+str(N)+file[:-7]+'.txt', header=False, index=False, sep=' ')\n",
    "\n",
    "#############################################################################################\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    matplotlib.rc('xtick',labelsize=10)\n",
    "    matplotlib.rc('ytick',labelsize=10)\n",
    "    \n",
    "    x=np.arange(totalhours)\n",
    "\n",
    "    pvalue = df.loc[hour-1, 'pvalue']\n",
    "    if pvalue < 0.0001:\n",
    "        pvalue_str = \"<0.0001\"\n",
    "    else:\n",
    "        pvalue_str = \"{:.3g}\".format(pvalue)\n",
    "\n",
    "    \n",
    "    font=12\n",
    "    \n",
    "    if meth in [4,5]:\n",
    "    \n",
    "      fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "\n",
    "      x = np.arange(totalhours)\n",
    "      \n",
    "      from matplotlib.cm import get_cmap\n",
    "      cmap = get_cmap('viridis')\n",
    "      colors = [cmap(i / (len(parameter_names)-1)) for i in range(len(parameter_names))]\n",
    "      #colors = ['b','g','r','c','m','y']\n",
    "      colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
    "      for i in range(len(parameter_names)):     \n",
    "        axs[0,0].plot(x,[abs(importance_list[j][i]) for j in range(totalhours)],label=parameter_names[i],color=colors[i])  \n",
    "      \n",
    "      axs[0,0].set_xlabel(\"Time\",fontsize=12)\n",
    "      axs[0,0].set_ylabel(\"Importance\",fontsize=12)\n",
    "      axs[0,0].set_title('Importance time evolution',fontsize=12)\n",
    "      axs[0,0].legend(prop={'size':10, 'weight':'normal'}, ncol=4, loc='upper center', bbox_to_anchor=(0.5, 0.99))\n",
    "      axs[0,0].grid(True)\n",
    "\n",
    "      ln1 =axs[0,1].plot(df.index, df['score'], color=colors[0], label='Score')\n",
    "      ln2 =axs[0,1].plot(df.index, df['mse'], color=colors[1], label='MSE')\n",
    "      ln3 =axs[0,1].plot(df.index, df['mae'], color=colors[2], label='MAE')\n",
    "      twin=axs[0,1].twinx()\n",
    "      ln4 =twin.plot(df.index, df['pvalue'], color=colors[3], label='p-value')\n",
    "      twin.set_ylabel('p-value',fontsize=12)\n",
    "      twin.set_ylim(0, 1e-15)\n",
    "      axs[0,1].set_xlabel('Time',fontsize=12)\n",
    "      axs[0,1].set_ylabel('Value',fontsize=12)\n",
    "      axs[0,1].set_title('Metrics time evolution',fontsize=12)\n",
    "      axs[0,1].set_ylim(0, 1)\n",
    "      lns = ln1 + ln2 + ln3 + ln4\n",
    "      labels = [l.get_label() for l in lns]\n",
    "      axs[0,1].legend(lns,labels,prop={'size':10,'weight':'normal'},loc='upper center', bbox_to_anchor=(0.15, 0.8))\n",
    "      axs[0,1].grid(True)\n",
    "\n",
    "      axs[1,0].scatter(ytest[hour-1], ypred[hour-1])\n",
    "      ideal = [min(ytest[hour-1]), max(ytest[hour-1])]\n",
    "      axs[1,0].plot(ideal, ideal, 'r--')\n",
    "      axs[1,0].set_xlabel('True Values',fontsize=12)\n",
    "      axs[1,0].set_ylabel('Predictions',fontsize=12)\n",
    "      axs[1,0].set_title('Hour: {}; Performance (score: {:.2f} [p: {}], mse: {:.2f}, mae: {:.2f})'.format(hour-1, df.loc[hour-1, 'score'], pvalue_str, df.loc[hour-1, 'mse'], df.loc[hour-1, 'mae']))\n",
    "      axs[1,0].grid(True)\n",
    "\n",
    "      axs[1,1].bar(parameter_names,importance_list[hour-1])\n",
    "      axs[1,1].set_xticklabels(parameter_names, rotation=90, ha='right')\n",
    "      axs[1,1].set_xlabel(\"Features\",fontsize=12)\n",
    "      axs[1,1].set_ylabel(\"Coefficient\",fontsize=12)\n",
    "      axs[1,1].set_title('Hour: '+str(hour-1)+'; Sobol total index',fontsize=12)\n",
    "      axs[1,1].grid(True)\n",
    "\n",
    "      import seaborn as sns\n",
    "      file_path = os.path.join(output_path, f'interactions_matrix_{hour-1}.txt')\n",
    "      inter_mat = np.loadtxt(file_path, delimiter='\\t')\n",
    "      sns.heatmap(inter_mat, annot=True, cmap='coolwarm', fmt=\".3f\", cbar_kws={'label': 'Sobol second order index'},\n",
    "                  xticklabels=parameter_names, yticklabels=parameter_names, ax=axs[2, 0])\n",
    "      axs[2, 0].set_title(f'Interactions Matrix {hour-1}',fontsize=12)\n",
    "      \n",
    "      \n",
    "      axs[2,1].bar(parameter_names,first_ord[hour-1])\n",
    "      axs[2,1].set_xticklabels(parameter_names, rotation=90, ha='right')\n",
    "      axs[2,1].set_xlabel(\"Features\",fontsize=12)\n",
    "      axs[2,1].set_ylabel(\"Coefficient\",fontsize=12)\n",
    "      axs[2,1].set_title('Hour: '+str(hour-1)+'; Sobol first order index',fontsize=12)    \n",
    "      axs[2,1].grid(True)\n",
    "\n",
    "    else:\n",
    "      fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "      x = np.arange(totalhours)\n",
    "      \n",
    "      from matplotlib.cm import get_cmap\n",
    "      cmap = get_cmap('viridis')\n",
    "      \n",
    "      \n",
    "      colorsfill = plt.cm.tab10(np.linspace(0, 1, 6))\n",
    "      colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
    "      for i in range(len(parameter_names)):    \n",
    "        axs[0,0].plot(x,[abs(importance_list[j][i]) for j in range(totalhours)],label=parameter_names[i],color=colors[i]) \n",
    "      \n",
    "      axs[0,0].set_xlabel(\"Time\",fontsize=12)\n",
    "      axs[0,0].set_ylabel(\"Importance\",fontsize=12)\n",
    "      axs[0,0].set_title('Importance time evolution',fontsize=12)\n",
    "      axs[0,0].set_ylim(0, 1)\n",
    "      axs[0,0].legend(prop={'size':10, 'weight':'normal'}, ncol=4, loc='upper center', bbox_to_anchor=(0.5, 0.99))\n",
    "      axs[0,0].grid(True)\n",
    "      \n",
    "      ln1 =axs[0,1].plot(df.index, df['score'], color=colors[0], label='Score')\n",
    "      ln2 =axs[0,1].plot(df.index, df['mse'], color=colors[1], label='MSE')\n",
    "      ln3 =axs[0,1].plot(df.index, df['mae'], color=colors[2], label='MAE')\n",
    "      twin=axs[0,1].twinx()\n",
    "      ln4 =twin.plot(df.index, df['pvalue'], color=colors[3], label='p-value')\n",
    "      twin.set_ylabel('p-value',fontsize=12)\n",
    "      twin.set_ylim(0, 1e-15)\n",
    "      axs[0,1].set_xlabel('Time',fontsize=12)\n",
    "      axs[0,1].set_ylabel('Value',fontsize=12)\n",
    "      axs[0,1].set_title('Metrics time evolution',fontsize=12)\n",
    "      axs[0,1].set_ylim(0, 1)\n",
    "      lns = ln1 + ln2 + ln3 + ln4\n",
    "      labels = [l.get_label() for l in lns]\n",
    "      axs[0,1].legend(lns,labels,prop={'size':10,'weight':'normal'},loc='upper center', bbox_to_anchor=(0.15, 0.8))\n",
    "      axs[0,1].grid(True)\n",
    "      \n",
    "      axs[1,0].scatter(ytest[hour-1], ypred[hour-1])\n",
    "      ideal = [min(ytest[hour-1]), max(ytest[hour-1])]\n",
    "      axs[1,0].plot(ideal, ideal, 'r--')\n",
    "      axs[1,0].set_xlabel('True Values',fontsize=12)\n",
    "      axs[1,0].set_ylabel('Predictions',fontsize=12)\n",
    "      axs[1,0].set_title('Hour: {}; Performance (score: {:.2f} [p: {}], mse: {:.2f}, mae: {:.2f})'.format(hour-1, df.loc[hour-1, 'score'], pvalue_str, df.loc[hour-1, 'mse'], df.loc[hour-1, 'mae']))\n",
    "      axs[1,0].grid(True)\n",
    "      \n",
    "      axs[1,1].bar(parameter_names,abs(importance_list[hour-1]))\n",
    "      \n",
    "      axs[1,1].set_xlabel(\"Features\",fontsize=12)\n",
    "      axs[1,1].set_xticklabels(parameter_names, rotation=90, ha='right')\n",
    "      axs[1,1].set_ylabel(\"Coefficient\",fontsize=12)\n",
    "      axs[1,1].set_title('Hour: '+str(hour-1)+'; Feature importance',fontsize=12)\n",
    "      axs[1,1].grid(True)\n",
    "      \n",
    "    fig.suptitle(method + ' on ' + name[:-9] + ' N:'+ str(N) + ' v:' + str(vpoint), fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/dario/Downloads/' +method+'_'+name[:-9] +'_hour'+str(hour-1)+ '_v'+str(vpoint)+'.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "  return predict_and_plot\n",
    "########################################################################\n",
    "\n",
    "def nearest_divisible(n , lst):\n",
    "  size = len(lst)\n",
    "  remainder = n % (size+2)\n",
    "  if remainder == 0:\n",
    "    return n\n",
    "  diff = size - remainder\n",
    "  return n + diff\n",
    "\n",
    "n_sample_calc = nearest_divisible(1000, parameter_names)\n",
    "\n",
    "choices=['vpoint','hpoint','variable','N_simul','method','hour','tuning']\n",
    "vpointmin=1;\n",
    "vpointmax=verticalmax;\n",
    "hpointmin=1;\n",
    "hpointmax=len(regions);\n",
    "varmin=1;\n",
    "varmax=len(variables);\n",
    "Nmin=totalsim*1/10;\n",
    "Nmax=totalsim;\n",
    "methmin=1;\n",
    "methmax=7; ###\n",
    "tunmin=0;\n",
    "tunmax=2;\n",
    "hourmin=1;\n",
    "hourmax=totalhours;\n",
    "Xmin=[vpointmin,hpointmin,varmin,Nmin,methmin,hourmin,tunmin]\n",
    "Xmax=[vpointmax,hpointmax,varmax,Nmax,methmax,hourmax,tunmax]\n",
    "Nstep=[verticalmax-1,hpointmax-1,varmax-1, (Nmax - Nmin) // 10, methmax-1, totalhours-1 , tunmax]\n",
    "\n",
    "def interactive_global(on_change_global,meth,N,var,hpoint,vpoint,hour,tun):\n",
    "\n",
    "    Xnew=[vpoint,hpoint,var,N,meth,hour,tun]\n",
    "\n",
    "    sliders = {}\n",
    "    for i, f in enumerate(choices):\n",
    "        sliders[f] = widgets.FloatSlider(\n",
    "            value=Xnew[i],\n",
    "            min=Xmin[i],\n",
    "            max=Xmax[i],\n",
    "            step=(Xmax[i] - Xmin[i]) / Nstep[i],\n",
    "            description=f\"{f}\",\n",
    "            readout_format=\".1f\",\n",
    "            layout={'width': '500px', 'margin': '0px 0px 0px 20px'}\n",
    "        )\n",
    "\n",
    "\n",
    "    # setup ui\n",
    "    out = widgets.interactive_output(on_change_global, sliders)    \n",
    "    controls = widgets.VBox(list(sliders.values()))\n",
    "    controls.layout = widgets.Layout(width='50%', align_items='center', justify_content='space-between')\n",
    "    title = widgets.HTML(\"<h1 style='margin-top: 20px; text-align: center; font-family: Arial, sans-serif; font-size: 36px;'>ML-AMPSIT</h1>\")\n",
    "    subtitle = widgets.HTML(\"<h2 style='margin-bottom: 20px; text-align: center;'>Machine Learning-based Automated Multi-method Parameter Sensitivity and Importance analysis Tool</h2>\")\n",
    "    subtitle2 = widgets.HTML(\"<h3 style='margin-bottom: 5px; text-align: center;'>interactive UI made by Dario Di Santo, Department of Civil, Environmental and Mechanical Engineering, University of Trento, Trento, Italy</h3>\")\n",
    "    subtitle3 = widgets.HTML(\"<h4 style='margin-bottom: 5px; text-align: center;'>How the script works: The first time it is used, option 1 (initialization) must be set to correctly initialize all variables; then change the value of the sliders on the UI and run the script again with option 2 (customization). This will re-run the methods with the custom values. All subsequent customizations must be run with option 2. More about this work at the following link: <a href='https://github.com/ML-AMPSIT/ML-AMPSIT'>Github repository</a> </h4>\")\n",
    "    label3_text = \"<b>variable:</b> \" + \", \".join(variables)\n",
    "    label3 = widgets.HTML(label3_text)\n",
    "    label4 = widgets.HTML('<b>Number of simulations:</b> change simulations amount for convergence analysis')\n",
    "    label5 = widgets.HTML('<b>method:</b> (1)Random Forest, (2)Lasso, (3)Support Vector Regression, (4)Bayesian regression, (5)Gaussian regression, (6)XGBoost, (7)CART')\n",
    "    label1_text = f\"<b>vertical levels:</b> {verticalmax}\"\n",
    "    label1 = widgets.HTML(label1_text)\n",
    "    label2_text = \"<b>domain horizontal point:</b> \" + \", \".join(regions)\n",
    "    label2 = widgets.HTML(label2_text)\n",
    "    label6 = widgets.HTML('<b>hour:</b> select an hour of interest to show associated metrics and importance ranking')\n",
    "    label7 = widgets.HTML('<b>tun:</b> tuning option: (0)off, (1)on, (2)load')\n",
    "    ui = widgets.VBox([widgets.HTML('<br>'), title, subtitle,subtitle2,subtitle3, widgets.HTML('<br>'), \n",
    "                      widgets.HBox([controls,widgets.VBox([label1, label2, label3, label4, label5, label6, label7])]),\n",
    "                      widgets.HTML('<br>'), out])\n",
    "    display(ui)\n",
    "    return sliders\n",
    "\n",
    "\n",
    "while True:\n",
    "    init = input(\"initialization=1 , customization=2 : \")\n",
    "    if init == \"1\" or init == \"2\":\n",
    "        break\n",
    "    print(\"Valore non valido, inserisci 1 o 2.\")\n",
    "if init == \"1\":  \n",
    "  on_change_global=create_predict_and_plot_global(meth=1, N=totalsim, var=1, hpoint=1, vpoint=1, hour=totalhours, tun=0, n_sample=n_sample_calc)\n",
    "  sliders=interactive_global(on_change_global,meth=1, N=totalsim, var=1, hpoint=1, vpoint=1, hour=totalhours, tun=0)  \n",
    "\n",
    "elif init==\"2\":\n",
    "  meth = int(sliders['method'].value)\n",
    "  N = int(sliders['N_simul'].value)\n",
    "  var = int(sliders['variable'].value)\n",
    "  hpoint = int(sliders['hpoint'].value)\n",
    "  vpoint = int(sliders['vpoint'].value)\n",
    "  hour = int(sliders['hour'].value)\n",
    "  tun = int(sliders['tuning'].value)\n",
    "\n",
    "  on_change_global=create_predict_and_plot_global(meth=meth, N=N, var=var, hpoint=hpoint,vpoint=vpoint,hour=hour, tun=tun, n_sample=n_sample_calc)\n",
    "\n",
    "  sliders=interactive_global(on_change_global,meth=meth, N=N, var=var, hpoint=hpoint, vpoint=vpoint, hour=hour, tun=tun)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
